{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-23T15:33:51.602016Z","iopub.execute_input":"2023-09-23T15:33:51.602387Z","iopub.status.idle":"2023-09-23T15:33:51.613015Z","shell.execute_reply.started":"2023-09-23T15:33:51.602358Z","shell.execute_reply":"2023-09-23T15:33:51.611924Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e16/sample_submission.csv\n/kaggle/input/playground-series-s3e16/train.csv\n/kaggle/input/playground-series-s3e16/test.csv\n/kaggle/input/crab-ckpt-47epoch/model_0_47\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Configuration**","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.0001\nn_epoch = 30000\nbatch_size = 100\nvalid_ratio = 0.8\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.615194Z","iopub.execute_input":"2023-09-23T15:33:51.615649Z","iopub.status.idle":"2023-09-23T15:33:51.629715Z","shell.execute_reply.started":"2023-09-23T15:33:51.615613Z","shell.execute_reply":"2023-09-23T15:33:51.628697Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# load csv as dataframe\ntrain_data=pd.read_csv('/kaggle/input/playground-series-s3e16/train.csv')\nprint(\"train data\")\nprint(train_data.tail())\ntest_data=pd.read_csv('/kaggle/input/playground-series-s3e16/test.csv')\nprint(\"test data\")\nprint(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.630594Z","iopub.execute_input":"2023-09-23T15:33:51.630925Z","iopub.status.idle":"2023-09-23T15:33:51.800699Z","shell.execute_reply.started":"2023-09-23T15:33:51.630892Z","shell.execute_reply":"2023-09-23T15:33:51.799705Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"train data\n          id Sex  Length  Diameter  Height     Weight  Shucked Weight  \\\n74046  74046   F  1.6625    1.2625  0.4375  50.660556       20.680960   \n74047  74047   I  1.0750    0.8625  0.2750  10.446791        4.323299   \n74048  74048   F  1.4875    1.2000  0.4125  29.483480       12.303683   \n74049  74049   I  1.2125    0.9625  0.3125  16.768729        8.972617   \n74050  74050   I  0.9125    0.6750  0.2000   5.386405        2.055339   \n\n       Viscera Weight  Shell Weight  Age  \n74046       10.361742     12.332033   10  \n74047        2.296310      3.543687    6  \n74048        7.540967      8.079607   10  \n74049        2.919999      4.280774    8  \n74050        1.034757      1.700970    6  \ntest data\n      id Sex  Length  Diameter  Height     Weight  Shucked Weight  \\\n0  74051   I  1.0500    0.7625  0.2750   8.618248        3.657085   \n1  74052   I  1.1625    0.8875  0.2750  15.507176        7.030676   \n2  74053   F  1.2875    0.9875  0.3250  14.571643        5.556502   \n3  74054   F  1.5500    0.9875  0.3875  28.377849       13.380964   \n4  74055   I  1.1125    0.8500  0.2625  11.765042        5.528153   \n\n   Viscera Weight  Shell Weight  \n0        1.729319      2.721552  \n1        3.246018      3.968930  \n2        3.883882      4.819415  \n3        6.548735      7.030676  \n4        2.466407      3.331066  \n","output_type":"stream"}]},{"cell_type":"code","source":"# analyze the correlation\nprint(train_data.corr(numeric_only=True))\n# feature extraction\nfeature_list = [\"Length\",\"Diameter\",\"Height\",\"Weight\",\"Shucked Weight\",\"Viscera Weight\",\"Shell Weight\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.803818Z","iopub.execute_input":"2023-09-23T15:33:51.804175Z","iopub.status.idle":"2023-09-23T15:33:51.842789Z","shell.execute_reply.started":"2023-09-23T15:33:51.804147Z","shell.execute_reply":"2023-09-23T15:33:51.841890Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"                      id    Length  Diameter    Height    Weight  \\\nid              1.000000  0.000165  0.000290  0.000967 -0.000910   \nLength          0.000165  1.000000  0.989437  0.918352  0.936374   \nDiameter        0.000290  0.989437  1.000000  0.921353  0.938249   \nHeight          0.000967  0.918352  0.921353  1.000000  0.901775   \nWeight         -0.000910  0.936374  0.938249  0.901775  1.000000   \nShucked Weight -0.000801  0.915516  0.914199  0.864083  0.971267   \nViscera Weight -0.000640  0.917855  0.918351  0.883127  0.971062   \nShell Weight   -0.000816  0.916957  0.922688  0.903398  0.965525   \nAge             0.000089  0.612843  0.621256  0.638067  0.601195   \n\n                Shucked Weight  Viscera Weight  Shell Weight       Age  \nid                   -0.000801       -0.000640     -0.000816  0.000089  \nLength                0.915516        0.917855      0.916957  0.612843  \nDiameter              0.914199        0.918351      0.922688  0.621256  \nHeight                0.864083        0.883127      0.903398  0.638067  \nWeight                0.971267        0.971062      0.965525  0.601195  \nShucked Weight        1.000000        0.942626      0.910398  0.503320  \nViscera Weight        0.942626        1.000000      0.933919  0.576808  \nShell Weight          0.910398        0.933919      1.000000  0.663473  \nAge                   0.503320        0.576808      0.663473  1.000000  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**custom dataset**","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass CrabAgeDataset(Dataset):\n    def __init__(self, data):\n        \"\"\"\n        data: dataframe\n        \"\"\"\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        \"\"\"\n        return the row as a dictionary \n        \"\"\"\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        #idx=str(idx)\n        sample=self.data.iloc[idx]\n        return sample.to_dict()\n\n#randomly split train data into training set and validation set\nvalid_data=train_data.sample(frac=valid_ratio)\ntrain_data=train_data.drop(valid_data.index)\n#load dataframe into dataset\ntrain_data=CrabAgeDataset(train_data)\nvalid_data=CrabAgeDataset(valid_data)\n#test_data=CrabAgeDataset(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.844811Z","iopub.execute_input":"2023-09-23T15:33:51.845530Z","iopub.status.idle":"2023-09-23T15:33:51.865480Z","shell.execute_reply.started":"2023-09-23T15:33:51.845494Z","shell.execute_reply":"2023-09-23T15:33:51.864390Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nclass LinearRegression(nn.Module):\n    def __init__(self, input_dim=7, output_dim=1):\n        super(LinearRegression, self).__init__()\n        self.layers=nn.Sequential(\n            nn.Linear(input_dim,64),\n            nn.ReLU(),\n            nn.Linear(64,32),\n            nn.ReLU(),\n            nn.Linear(32,16),\n            nn.ReLU(),\n            nn.Linear(16,1)\n        )\n    def forward(self,x):\n        return self.layers(x)\n    \nmodel=LinearRegression()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.867312Z","iopub.execute_input":"2023-09-23T15:33:51.867936Z","iopub.status.idle":"2023-09-23T15:33:51.877015Z","shell.execute_reply.started":"2023-09-23T15:33:51.867902Z","shell.execute_reply":"2023-09-23T15:33:51.875984Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**loss function and optimizer**","metadata":{}},{"cell_type":"code","source":"import torch\nloss_fn = nn.L1Loss()#MAE\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.878290Z","iopub.execute_input":"2023-09-23T15:33:51.878838Z","iopub.status.idle":"2023-09-23T15:33:51.887064Z","shell.execute_reply.started":"2023-09-23T15:33:51.878804Z","shell.execute_reply":"2023-09-23T15:33:51.886010Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_data, batch_size=batch_size,shuffle=True, num_workers=0)\nvalid_dataloader = DataLoader(valid_data, batch_size=batch_size,shuffle=True, num_workers=0)\n#test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True, num_workers=0)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.889962Z","iopub.execute_input":"2023-09-23T15:33:51.890337Z","iopub.status.idle":"2023-09-23T15:33:51.898712Z","shell.execute_reply.started":"2023-09-23T15:33:51.890303Z","shell.execute_reply":"2023-09-23T15:33:51.897614Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print(type(train_data))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.903226Z","iopub.execute_input":"2023-09-23T15:33:51.904025Z","iopub.status.idle":"2023-09-23T15:33:51.911199Z","shell.execute_reply.started":"2023-09-23T15:33:51.903993Z","shell.execute_reply":"2023-09-23T15:33:51.909842Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"<class '__main__.CrabAgeDataset'>\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_one_epoch(epoch_index):\n    running_loss=0\n    last_loss=0\n    \n    for i, sample in enumerate(train_dataloader):\n               \n        # Zero your gradients for every batch!\n        optimizer.zero_grad()\n    \n        #get inputs and labelss\n        inputs=[]\n        labels=sample['Age']\n        batch_num=len(labels)\n        labels=torch.tensor(labels,dtype=torch.float32)\n        #labels=torch.transpose(labels,dim0=0,dim)\n        #print(labels.shape)\n        labels=labels.view(batch_num,1)\n        #feature extraction\n        for feature in feature_list:\n            inputs.append(torch.tensor(sample[feature],dtype=torch.float32))\n        #inputs=torch.FloatTensor(inputs)\n    \n\n        \n        # Make predictions for this batch\n        #print(inputs)\n        inputs=torch.stack(inputs,dim=1)\n        \n        inputs.to(torch.device(\"cuda\"))\n        labels.to(torch.device(\"cuda\"))\n        if i==1:\n            pass\n            #print(batch_num)\n            #print(inputs.shape)\n            #print(labels.shape)\n        #inputs=torch.transpose(inputs,dim0=0,dim1=1)\n        #print(inputs.shape)\n        #print(labels)\n        #print(inputs)\n        outputs = model(inputs)\n\n\n        # Compute the loss and its gradients\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n\n        # Adjust learning weights\n        optimizer.step()\n\n        # Gather data and report\n        running_loss += loss.item()\n        if i % 1000 == 999:\n            last_loss = running_loss / 1000 # loss per batch\n            print('  batch {} loss: {}'.format(i + 1, last_loss))\n            tb_x = epoch_index * len(train_loader) + i + 1\n            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n            running_loss = 0.\n\n    return last_loss\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.913238Z","iopub.execute_input":"2023-09-23T15:33:51.913653Z","iopub.status.idle":"2023-09-23T15:33:51.926997Z","shell.execute_reply.started":"2023-09-23T15:33:51.913622Z","shell.execute_reply":"2023-09-23T15:33:51.926203Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#import datetime\n# Initializing in a separate cell so we can easily add more epochs to the same run\n#timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n#writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\nepoch_number = 0\n\nEPOCHS = 5\n\nbest_vloss = 1_000_000.\n\nfor epoch in range(EPOCHS):\n    print('EPOCH {}:'.format(epoch_number + 1))\n\n    # Make sure gradient tracking is on, and do a pass over the data\n    model.train(True)\n    avg_loss = train_one_epoch(epoch_number)\n\n\n    running_vloss = 0.0\n    # Set the model to evaluation mode, disabling dropout and using population\n    # statistics for batch normalization.\n    model.eval()\n\n    # Disable gradient computation and reduce memory consumption.\n    with torch.no_grad():\n        for i, vsample in enumerate(valid_dataloader):\n            #get inputs and labelss\n            vinputs=[]\n            vlabels=vsample['Age']\n            batch_num=len(vlabels)\n            vlabels=torch.tensor(vlabels,dtype=torch.float32)\n            #labels=torch.transpose(labels,dim0=0,dim)\n            #print(labels.shape)\n            vlabels=vlabels.view(batch_num,1)\n            #feature extraction\n            for feature in feature_list:\n                vinputs.append(torch.tensor(vsample[feature],dtype=torch.float32))\n            #inputs=torch.FloatTensor(inputs)\n            vinputs=torch.stack(vinputs,dim=1)    \n            voutputs = model(vinputs)\n            vloss = loss_fn(voutputs, vlabels)\n            running_vloss += vloss\n\n    avg_vloss = running_vloss / (i + 1)\n    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n\n    # Log the running loss averaged per batch\n    # for both training and validation\n    \"\"\"\n    writer.add_scalars('Training vs. Validation Loss',\n                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n                    epoch_number + 1)\n    writer.flush()\n    \"\"\"\n\n    # Track best performance, and save the model's state\n    if avg_vloss < best_vloss:\n        best_vloss = avg_vloss\n        model_path = 'model_{}_{}'.format(0, epoch_number)\n        torch.save(model.state_dict(), model_path)\n\n    epoch_number += 1","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:33:51.928600Z","iopub.execute_input":"2023-09-23T15:33:51.929313Z","iopub.status.idle":"2023-09-23T15:34:36.326767Z","shell.execute_reply.started":"2023-09-23T15:33:51.929281Z","shell.execute_reply":"2023-09-23T15:34:36.325667Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"EPOCH 1:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_28/3933569416.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels=torch.tensor(labels,dtype=torch.float32)\n/tmp/ipykernel_28/3933569416.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs.append(torch.tensor(sample[feature],dtype=torch.float32))\n/tmp/ipykernel_28/673332635.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  vlabels=torch.tensor(vlabels,dtype=torch.float32)\n/tmp/ipykernel_28/673332635.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  vinputs.append(torch.tensor(vsample[feature],dtype=torch.float32))\n","output_type":"stream"},{"name":"stdout","text":"LOSS train 0 valid 5.507346153259277\nEPOCH 2:\nLOSS train 0 valid 3.128234624862671\nEPOCH 3:\nLOSS train 0 valid 3.0290915966033936\nEPOCH 4:\nLOSS train 0 valid 2.918623447418213\nEPOCH 5:\nLOSS train 0 valid 2.7789225578308105\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**inference**","metadata":{}},{"cell_type":"code","source":"our_model=LinearRegression(7,1)\nour_model.load_state_dict(torch.load(\"/kaggle/input/crab-ckpt-47epoch/model_0_47\"))\n#print(test_data.head())\ntest_inputs=[]\nfor i in test_data.index:\n    features=[]\n    for f in feature_list:\n        features.append(test_data[f][i])\n    test_inputs.append(torch.tensor(features,dtype=torch.float32))\ntest_inputs=torch.stack(test_inputs,dim=1)\ntest_inputs=torch.transpose(test_inputs,0,1)\nprint(test_inputs.shape)\ntest_results=our_model(test_inputs)\nprint(test_results.shape)\nprint(test_results)\n#for i, sample in enumerate(test_data):\n    #test_inputs=[]\n    #for feature in feature_list:\n    #inputs.append(torch.tensor(sample[feature],dtype=torch.float32))\n        #inputs=torch.FloatTensor(inputs)\n    \n\n        \n        # Make predictions for this batch\n        #print(inputs)\n        #inputs=torch.stack(inputs,dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:34:36.328371Z","iopub.execute_input":"2023-09-23T15:34:36.328733Z","iopub.status.idle":"2023-09-23T15:34:36.587228Z","shell.execute_reply.started":"2023-09-23T15:34:36.328699Z","shell.execute_reply":"2023-09-23T15:34:36.585748Z"},"trusted":true},"execution_count":48,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     features\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feature_list:\n\u001b[0;32m----> 8\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m[i])\n\u001b[1;32m      9\u001b[0m     test_inputs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(features,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     10\u001b[0m test_inputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mstack(test_inputs,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3718\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3715\u001b[0m key \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(key)\n\u001b[1;32m   3716\u001b[0m key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 3718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3719\u001b[0m     \u001b[38;5;66;03m# is_iterator to exclude generator e.g. test_getitem_listlike\u001b[39;00m\n\u001b[1;32m   3720\u001b[0m     \u001b[38;5;66;03m# shortcut if the key is in columns\u001b[39;00m\n\u001b[1;32m   3721\u001b[0m     is_mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n\u001b[1;32m   3722\u001b[0m     \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[1;32m   3723\u001b[0m     \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/inference.py:360\u001b[0m, in \u001b[0;36mis_hashable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# which can be faster than calling hash. That is because numpy scalars\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# fail this test.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Reconsider this decision once this numpy bug is fixed:\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# https://github.com/numpy/numpy/issues/5562\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"path = '/kaggle/working/output.txt'\nf = open(path, 'w')\nprint('id,yield', file=f)\nfor i in test_data.index:\n    print(\"{},{}\".format(i,test_results[i].item()),file=f)\n    #print(i,1,\",\",test_results[i].item(), file=f)\nprint('etc.', file=f)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:34:36.588357Z","iopub.status.idle":"2023-09-23T15:34:36.588914Z","shell.execute_reply.started":"2023-09-23T15:34:36.588654Z","shell.execute_reply":"2023-09-23T15:34:36.588676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yield_list=[]\nfor i in test_data.index:\n    yield_list.append(test_results[i].item())\nresult={\n    \"id\":test_data[\"id\"],\n    \"yield\":yield_list\n}\nresult=pd.DataFrame(result)\nprint(result)\nresult.to_csv(\"/kaggle/working/result.csv\")\n#test_data.to_csv(\"/kaggle/working/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T15:35:19.911660Z","iopub.execute_input":"2023-09-23T15:35:19.912029Z","iopub.status.idle":"2023-09-23T15:35:20.443230Z","shell.execute_reply.started":"2023-09-23T15:35:19.911996Z","shell.execute_reply":"2023-09-23T15:35:20.441922Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"           id      yield\n0       74051   7.543072\n1       74052   7.853662\n2       74053   9.673781\n3       74054   9.180499\n4       74055   7.557554\n...       ...        ...\n49363  123414   8.671449\n49364  123415   7.805567\n49365  123416  11.743745\n49366  123417   9.339592\n49367  123418  12.010289\n\n[49368 rows x 2 columns]\n","output_type":"stream"}]}]}